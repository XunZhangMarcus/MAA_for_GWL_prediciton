import torch.nn.functional as F
import os
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import torch
import matplotlib.pyplot as plt
import logging
import pandas as pd

# å¹´åŒ–æ”¶ç›Š
def calculate_annualized_return(returns, periods_per_year=252):
    cumulative_return = np.prod([1 + r for r in returns]) - 1
    years = len(returns) / periods_per_year
    if years == 0:
        return 0
    annualized_return = (1 + cumulative_return) ** (1 / years) - 1
    return annualized_return * 100

# å¤æ™®æ¯”ç‡ï¼ˆé»˜è®¤æ— é£é™©åˆ©ç‡ä¸º0ï¼‰
def calculate_sharpe_ratio(returns, periods_per_year=252):
    excess_returns = np.array(returns)
    mean_excess = np.mean(excess_returns)
    std_excess = np.std(excess_returns)
    if std_excess == 0:
        return 0
    sharpe = (mean_excess * np.sqrt(periods_per_year)) / std_excess
    return sharpe


# æœ€å¤§å›æ’¤
# def calculate_max_drawdown(returns):
#     cumulative_returns = np.cumprod([1 + r for r in returns])
#     peak = np.maximum.accumulate(cumulative_returns)
#     drawdowns = (cumulative_returns - peak) / peak
#     max_drawdown = np.min(drawdowns)
#     return abs(max_drawdown) * 100


def calculate_max_drawdown(returns):
    """
    è®¡ç®—æœ€å¤§å›æ’¤ï¼ˆå†å²æœ€é«˜ç‚¹ä¹‹åçš„æœ€å°å€¼ä¹‹é—´çš„è·Œå¹…ï¼‰
    è¿”å›å•ä½ä¸ºç™¾åˆ†æ¯”ï¼ˆæ­£æ•°ï¼‰

    Parameters:
    - returns: æ”¶ç›Šç‡åºåˆ—ï¼ˆçº¿æ€§ï¼‰

    Returns:
    - æœ€å¤§å›æ’¤ï¼ˆ%ï¼‰
    """
    if len(returns) == 0:
        return np.nan

    returns = np.array(returns)
    cumulative_returns = np.cumprod(1 + returns)

    # æ‰¾å‡ºå†å²æœ€é«˜ç‚¹çš„ä½ç½®
    peak_index = np.argmax(cumulative_returns)

    # å¦‚æœ peak æ˜¯æœ€åä¸€ä¸ªç‚¹ï¼Œåé¢æ²¡æœ‰æœ€å°å€¼ï¼Œå›æ’¤ä¸º 0
    if peak_index == len(cumulative_returns) - 1:
        return 0.0

    # åœ¨ peak ä¹‹åæ‰¾æœ€å°å€¼
    min_after_peak = np.min(cumulative_returns[peak_index + 1:])
    peak_value = cumulative_returns[peak_index]

    # æœ€å¤§å›æ’¤ï¼šä» peak åˆ° min çš„ç™¾åˆ†æ¯”è·Œå¹…
    max_drawdown = (min_after_peak - peak_value) / peak_value

    return abs(max_drawdown) * 100

# èƒœç‡ï¼ˆå¯é€‰ï¼‰
def calculate_win_rate(returns):
    returns = np.array(returns)
    profitable_trades = np.sum(returns > 0)
    total_trades = np.sum(returns != 0)
    return (profitable_trades / total_trades) * 100 if total_trades > 0 else 0


def calculate_returns(prices, pred_labels):
    """
    è®¡ç®—ç»™å®šä»·æ ¼æ•°æ®å’Œé¢„æµ‹åŠ¨ä½œçš„å›æŠ¥ã€‚

    Args:
    - prices (np.array): ä»·æ ¼æ•°æ®ã€‚
    - pred_labels (np.array): é¢„æµ‹çš„åŠ¨ä½œæ ‡ç­¾ï¼Œ0 = hold, 1 = buy, 2 = sell

    Returns:
    - returns (list): å›æŠ¥åˆ—è¡¨ã€‚
    """
    returns = []
    for i in range(1, len(prices)):
        price_change = (prices[i] - prices[i - 1]) / prices[i - 1]
        action = pred_labels[i]
        if action == 1:  # åšå¤šï¼ˆBuyï¼‰
            returns.append(price_change)
        elif action == 2:  # åšç©ºï¼ˆSellï¼‰
            returns.append(-price_change)
        else:  # æŒæœ‰ï¼ˆHoldï¼‰
            returns.append(0)
    return returns


def calculate_returns_with_probabilities(prices, pred_probs):
    """
    è®¡ç®—ç»™å®šä»·æ ¼æ•°æ®å’Œé¢„æµ‹æ ‡ç­¾æ¦‚ç‡çš„å›æŠ¥ã€‚

    Args:
    - prices (np.array): ä»·æ ¼æ•°æ®ã€‚
    - pred_probs (np.array): é¢„æµ‹çš„æ ‡ç­¾æ¦‚ç‡ï¼Œshapeåº”ä¸º (n_samples, 3)ï¼Œ
                              æ¯ä¸€è¡Œåˆ†åˆ«è¡¨ç¤º [hold_prob, buy_prob, sell_prob]ã€‚

    Returns:
    - returns (list): å›æŠ¥åˆ—è¡¨ã€‚
    """

    # è®¡ç®—ä»·æ ¼å˜åŒ–
    price_change = (prices[:,-1,:] - prices[:,-2,:]) / prices[:,-2,:]
    price_change = price_change.detach().cpu().numpy().flatten()
    # è·å–é¢„æµ‹çš„æ¦‚ç‡
    hold_prob = pred_probs[:,0]
    buy_prob = pred_probs[:,1]
    sell_prob = pred_probs[:,2]

    # æ ¹æ®æ¦‚ç‡åŠ æƒè®¡ç®—å›æŠ¥
    weighted_return = hold_prob * 0 + buy_prob * price_change + sell_prob * (-price_change) # ndarrary 256
    return weighted_return


def calculate_metrics(returns, periods_per_year=252):
    """
    è®¡ç®—è´¢åŠ¡æŒ‡æ ‡ï¼ˆSharpe Ratio, Max Drawdown, Annualized Return, Win Rateï¼‰

    Args:
    - returns (list): å›æŠ¥æ•°æ®ã€‚
    - periods_per_year (int): æ¯å¹´äº¤æ˜“æ—¥æ•°ï¼ˆé»˜è®¤252ï¼‰ã€‚

    Returns:
    - metrics (dict): åŒ…å«è´¢åŠ¡æŒ‡æ ‡çš„å­—å…¸ã€‚
    """
    sharpe_ratio = calculate_sharpe_ratio(returns, periods_per_year)
    max_drawdown = calculate_max_drawdown(returns)
    annualized_return = calculate_annualized_return(returns, periods_per_year)
    win_rate = calculate_win_rate(returns)

    # è®¡ç®—å¡ç›æ¯”ï¼Œå¦‚æœæœ€å¤§å›æ’¤ä¸º0ï¼Œåˆ™è®¾ä¸ºæ— ç©·å¤§
    calmar_ratio = float('inf') if max_drawdown == 0 else annualized_return / max_drawdown

    return {
        'sharpe_ratio': round(sharpe_ratio, 4),
        'max_drawdown': round(max_drawdown, 2),
        'annualized_return': round(annualized_return, 2),
        'win_rate': round(win_rate, 2),
        'calmar_ratio': round(calmar_ratio, 2)
    }


def calculate_financial_loss(generators, train_x, train_y, y_scaler):
    values = []  # ç”¨äºä¿å­˜æ¯ä¸ªç”Ÿæˆå™¨çš„ MSE

    for i, generator in enumerate(generators):
        generator.eval()

        train_x_i = train_x[i]
        train_y_i = train_y[i]
        train_y_inv_i = inverse_transform_for_financial(train_y_i, y_scaler)

        with torch.no_grad():
            train_pred, train_pred_cls = generator(train_x_i)
            train_probs = torch.softmax(train_pred_cls, dim=-1).cpu().numpy()
            weighted_returns = calculate_returns_with_probabilities(train_y_inv_i, train_probs)
            value = weighted_returns.mean()
            values.append(value)
            return_tensor = torch.tensor(values, dtype=torch.float32)
    return return_tensor


def validate_financial_metric(generator, train_x, train_y, val_x, val_y, y_scaler):
    """
    éªŒè¯æ¨¡å‹çš„è´¢åŠ¡æŒ‡æ ‡ã€‚

    Args:
    - generator (torch.nn.Module): è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
    - train_x (torch.Tensor): è®­ç»ƒç‰¹å¾æ•°æ®ã€‚
    - train_y (torch.Tensor): è®­ç»ƒçœŸå®æ ‡ç­¾ã€‚
    - val_x (torch.Tensor): æµ‹è¯•ç‰¹å¾æ•°æ®ã€‚
    - val_y (torch.Tensor): æµ‹è¯•çœŸå®æ ‡ç­¾ã€‚
    - y_scaler (scaler): ç›®æ ‡æ•°æ®çš„æ ‡å‡†åŒ–å™¨ã€‚

    Returns:
    - train_metrics_list (list): è®­ç»ƒé›†çš„è´¢åŠ¡æŒ‡æ ‡åˆ—è¡¨ã€‚
    - val_metrics_list (list): æµ‹è¯•é›†çš„è´¢åŠ¡æŒ‡æ ‡åˆ—è¡¨ã€‚
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    generator.eval()
    device = train_x.device  # è·å–è¾“å…¥æ•°æ®çš„è®¾å¤‡

    # è·å–è®­ç»ƒå’Œæµ‹è¯•é›†çš„é¢„æµ‹
    with torch.no_grad():
        _, train_pred_labels = get_model_predictions(generator, train_x)
        _, test_pred_labels = get_model_predictions(generator, val_x)

    # åå‘å˜æ¢ç›®æ ‡å˜é‡ï¼ˆåœ¨CPUä¸Šè¿›è¡Œï¼‰
    train_y_inv = inverse_transform(train_y.cpu(), y_scaler)
    val_y_inv = inverse_transform(val_y.cpu(), y_scaler)

    # è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›æŠ¥
    train_returns = calculate_returns(train_y_inv.flatten(), train_pred_labels)
    test_returns = calculate_returns(val_y_inv.flatten(), test_pred_labels)

    # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
    train_metrics = calculate_metrics(train_returns)
    val_metrics = calculate_metrics(test_returns)

    return [train_metrics], [val_metrics]

def get_model_predictions(generator, x_data):
    """
    è·å–æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚

    Args:
    - generator (torch.nn.Module): è®­ç»ƒå¥½çš„ç”Ÿæˆå™¨æ¨¡å‹ã€‚
    - x_data (torch.Tensor): è¾“å…¥æ•°æ®ã€‚

    Returns:
    - pred (np.array): é¢„æµ‹çš„ç›®æ ‡å€¼ã€‚
    - pred_labels (np.array): é¢„æµ‹çš„åˆ†ç±»æ ‡ç­¾ã€‚
    """
    with torch.no_grad():
        pred, pred_cls = generator(x_data)
        pred = pred.cpu().numpy()
        pred_labels = pred_cls.argmax(dim=-1).cpu().numpy()
    return pred, pred_labels


def validate(model, val_x, val_y, val_label_y, predict_step=1, device='cuda'):
    model.eval()
    model = model.to(device)  # âœ… æ¨¡å‹ç§»åˆ° device
    with torch.no_grad():
        # âœ… æ‰€æœ‰æ•°æ®éƒ½ç§»åˆ° device
        val_x = val_x.clone().detach().float().to(device)

        if isinstance(val_y, np.ndarray):
            val_y = torch.tensor(val_y).float()
        val_y = val_y.clone().detach().float().to(device)

        if isinstance(val_label_y, np.ndarray):
            val_label_y = torch.tensor(val_label_y).long()
        val_label_y = val_label_y.clone().detach().long().to(device)

        # æ¨¡å‹é¢„æµ‹
        reg_preds, cls_preds = model(val_x)

        # é¢„æµ‹ & æ ‡ç­¾éƒ½åœ¨ device ä¸Šï¼Œæ­¤å¤„æ— éœ€å†è½¬
        reg_preds = reg_preds[:, -predict_step:]

        val_y = val_y[:, -predict_step:].squeeze(-1)
        if predict_step > 1:
            val_y = val_y.squeeze(dim=1)
        mse_loss = F.mse_loss(reg_preds, val_y)

        cls_preds = cls_preds[:, -predict_step:, :]
        cls_targets = val_label_y[:, -predict_step:]

        pred_labels = cls_preds.argmax(dim=-1)
        pred_labels = pred_labels.long()
        cls_targets = cls_targets.long()

        #print(pred_labels.shape, cls_targets.shape,cls_targets.numel())
        acc = (pred_labels == cls_targets).sum() / (cls_targets.numel())

    return mse_loss.item(), acc.item()


def validate_with_label(model, val_x, val_y, val_labels):
    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    with torch.no_grad():  # ç¦æ­¢è®¡ç®—æ¢¯åº¦
        val_x = val_x.clone().detach().float()

        # æ£€æŸ¥val_yçš„ç±»å‹ï¼Œå¦‚æœæ˜¯numpy.ndarrayåˆ™è½¬æ¢ä¸ºtorch.Tensor
        if isinstance(val_y, np.ndarray):
            val_y = torch.tensor(val_y).float()
        else:
            val_y = val_y.clone().detach().float()

        # labels ç”¨äºåˆ†ç±»
        if isinstance(val_labels, np.ndarray):
            val_lbl_t = torch.tensor(val_labels).long().to(val_x.device)
        else:
            val_lbl_t = val_labels.clone().detach().long().to(val_x.device)

        # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        predictions, logits  = model(val_x)
        predictions = predictions.cpu().numpy()
        val_y = val_y.cpu().numpy()

        # è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä½œä¸ºéªŒè¯æŸå¤±
        mse_loss = F.mse_loss(torch.tensor(predictions).float().squeeze(), torch.tensor(val_y).float().squeeze())

        true_cls = val_lbl_t[:, -1].squeeze()  # [B]
        pred_cls = logits.argmax(dim=1)  # [B]
        acc = (pred_cls == true_cls).float().mean()  # æ ‡é‡

        return mse_loss, acc

def print_metrics(results):
    print("ğŸ“Š å›æµ‹ç»“æœæŒ‡æ ‡ï¼ˆæ¯è½®ï¼‰")
    print("=" * 40)
    for i, result in enumerate(results):
        train_metrics = result['train_metrics']
        val_metrics = result['val_metrics']
        print(f"Generator {i+1}:")
        print("  ğŸ“˜ è®­ç»ƒé›†:")
        print(f"    Sharpe Ratio       : {train_metrics['sharpe_ratio']:.4f}")
        print(f"    Calmar Ratio       : {train_metrics['calmar_ratio']:.4f}")
        print(f"    Max Drawdown       : {train_metrics['max_drawdown']:.2f}%")
        print(f"    Annualized Return  : {train_metrics['annualized_return']:.2f}%")
        print(f"    Win Rate           : {train_metrics.get('win_rate', 'N/A')}%")
        print("  ğŸ“• æµ‹è¯•é›†:")
        print(f"    Sharpe Ratio       : {val_metrics['sharpe_ratio']:.4f}")
        print(f"    Calmar Ratio       : {val_metrics['calmar_ratio']:.4f}")
        print(f"    Max Drawdown       : {val_metrics['max_drawdown']:.2f}%")
        print(f"    Annualized Return  : {val_metrics['annualized_return']:.2f}%")
        print(f"    Win Rate           : {val_metrics.get('win_rate', 'N/A')}%")
        print("-" * 40)


def plot_generator_losses(data_G, output_dir):
    """
    ç»˜åˆ¶ G1ã€G2ã€G3 çš„æŸå¤±æ›²çº¿ã€‚

    Args:
        data_G1 (list): G1 çš„æŸå¤±æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å« [histD1_G1, histD2_G1, histD3_G1, histG1]ã€‚
        data_G2 (list): G2 çš„æŸå¤±æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å« [histD1_G2, histD2_G2, histD3_G2, histG2]ã€‚
        data_G3 (list): G3 çš„æŸå¤±æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å« [histD1_G3, histD2_G3, histD3_G3, histG3]ã€‚
    """

    plt.rcParams.update({'font.size': 12})
    all_data = data_G
    N = len(all_data)
    plt.figure(figsize=(6 * N, 5))

    for i, data in enumerate(all_data):
        plt.subplot(1, N, i + 1)
        for j, acc in enumerate(data):
            plt.plot(acc, label=f"G{i + 1} vs D{j + 1}" if j < N - 1 else f"G{i + 1} Combined", linewidth=2)

        plt.xlabel("Epoch", fontsize=14)
        plt.ylabel("Loss", fontsize=14)
        plt.title(f"G{i + 1} Loss over Epochs", fontsize=16)
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "generator_losses.png"), dpi=500)
    plt.close()


def plot_discriminator_losses(data_D, output_dir):
    plt.rcParams.update({'font.size': 12})
    N = len(data_D)
    plt.figure(figsize=(6 * N, 5))

    for i, data in enumerate(data_D):
        plt.subplot(1, N, i + 1)
        for j, acc in enumerate(data):
            plt.plot(acc, label=f"D{i + 1} vs G{j + 1}" if j < len(data)-1 else f"D{i + 1} Combined", linewidth=2)

        plt.xlabel("Epoch", fontsize=14)
        plt.ylabel("Loss", fontsize=14)
        plt.title(f"D{i + 1} Loss over Epochs", fontsize=16)
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "discriminator_losses.png"), dpi=500)
    plt.close()


def visualize_overall_loss(histG, histD, output_dir):
    plt.rcParams.update({'font.size': 12})
    N = len(histG)
    plt.figure(figsize=(5 * N, 4))

    for i, (g, d) in enumerate(zip(histG, histD)):
        plt.plot(g, label=f"G{i + 1} Loss", linewidth=2)
        plt.plot(d, label=f"D{i + 1} Loss", linewidth=2)

    plt.xlabel("Epoch", fontsize=14)
    plt.ylabel("Loss", fontsize=14)
    plt.title("Generator & Discriminator Loss", fontsize=16)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "overall_losses.png"), dpi=500)
    plt.close()


def plot_mse_loss(hist_MSE_G, hist_val_loss, num_epochs,
                  output_dir):
    """
    ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­å’ŒéªŒè¯é›†ä¸Šçš„MSEæŸå¤±å˜åŒ–æ›²çº¿

    å‚æ•°ï¼š
    hist_MSE_G1, hist_MSE_G2, hist_MSE_G3 : è®­ç»ƒè¿‡ç¨‹ä¸­å„ç”Ÿæˆå™¨çš„MSEæŸå¤±
    hist_val_loss1, hist_val_loss2, hist_val_loss3 : éªŒè¯é›†ä¸Šå„ç”Ÿæˆå™¨çš„MSEæŸå¤±
    num_epochs : è®­ç»ƒçš„epochæ•°
    """
    plt.rcParams.update({'font.size': 12})
    N = len(hist_MSE_G)
    plt.figure(figsize=(5 * N, 4))

    for i, (MSE, val_loss) in enumerate(zip(hist_MSE_G, hist_val_loss)):
        plt.plot(range(num_epochs), MSE, label=f"Train MSE G{i + 1}", linewidth=2)
        plt.plot(range(num_epochs), val_loss, label=f"Val MSE G{i + 1}", linewidth=2, linestyle="--")

    plt.title("MSE Loss for Generators (Train vs Validation)", fontsize=16)
    plt.xlabel("Epoch", fontsize=14)
    plt.ylabel("MSE", fontsize=14)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "mse_losses.png"), dpi=500)
    plt.close()


def inverse_transform(predictions, scaler):
    """ ä½¿ç”¨y_scaleré€†è½¬æ¢é¢„æµ‹ç»“æœ """
    # ç¡®ä¿æ•°æ®åœ¨CPUä¸Š
    if isinstance(predictions, torch.Tensor):
        predictions = predictions.cpu().numpy()

    original_shape = predictions.shape
    reshaped = predictions.reshape(-1, original_shape[-1])  # (batch * steps, 1)
    restored = scaler.inverse_transform(reshaped)
    return restored


def inverse_transform_for_financial(predictions, scaler):
    """
    åå½’ä¸€åŒ–é¢„æµ‹å€¼ï¼Œä¿æŒä¸è¾“å…¥å¼ é‡ç›¸åŒ shapeã€‚
    å‚æ•°ï¼š
        predictions: torch.Tensor, shape [B, T, C]
        scaler: sklearn çš„ scaler å®ä¾‹
    è¿”å›ï¼š
        numpy.ndarrayï¼Œshape åŒ predictions
    """
    assert predictions.ndim == 3 and predictions.shape[-1] == 1, "è¾“å…¥å¿…é¡»æ˜¯ [B, T, 1] å½¢çŠ¶"

    device = predictions.device
    original_shape = predictions.shape
    reshaped = predictions.detach().cpu().numpy().reshape(-1, 1)  # [B*T, 1]
    restored = scaler.inverse_transform(reshaped)  # [B*T, 1]
    restored = restored.reshape(original_shape)  # æ¢å¤ä¸º [B, T, 1]

    return torch.tensor(restored, dtype=predictions.dtype, device=device)


def compute_metrics(true_values, predicted_values):
    """è®¡ç®—MSE, MAE, RMSE, MAPE"""
    mse = mean_squared_error(true_values, predicted_values)
    mae = mean_absolute_error(true_values, predicted_values)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((true_values - predicted_values) / true_values)) * 100
    per_target_mse = np.mean((true_values - predicted_values) ** 2, axis=0)  # æ–°å¢
    return mse, mae, rmse, mape, per_target_mse


def plot_fitting_curve(true_values, predicted_values, output_dir, model_name):
    """ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿å¹¶ä¿å­˜ç»“æœ"""
    plt.rcParams.update({'font.size': 12})
    plt.figure(figsize=(10, 6))
    plt.plot(true_values, label='True Values', linewidth=2)
    plt.plot(predicted_values, label='Predicted Values', linewidth=2, linestyle='--')
    plt.title(f'{model_name} Fitting Curve', fontsize=16)
    plt.xlabel('Time', fontsize=14)
    plt.ylabel('Value', fontsize=14)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f'{output_dir}/{model_name}_fitting_curve.png', dpi=500)
    plt.close()


def save_metrics(metrics, output_dir, model_name):
    """ä¿å­˜MSE, MAE, RMSE, MAPEåˆ°æ–‡ä»¶"""
    with open(f'{output_dir}/{model_name}_metrics.txt', 'w') as f:
        f.write("MSE: {}\n".format(metrics[0]))
        f.write("MAE: {}\n".format(metrics[1]))
        f.write("RMSE: {}\n".format(metrics[2]))
        f.write("MAPE: {}\n".format(metrics[3]))


def evaluate_best_models(generators, best_model_state, train_xes, train_y, test_xes, test_y, y_scaler, output_dir):
    N = len(generators)

    # åŠ è½½æ¨¡å‹å¹¶è®¾ä¸º eval
    for i in range(N):
        generators[i].load_state_dict(best_model_state[i])
        generators[i].eval()

    train_y_inv = inverse_transform(train_y, y_scaler)
    test_y_inv = inverse_transform(test_y, y_scaler)

    train_preds_inv = []
    test_preds_inv = []
    train_metrics_list = []
    test_metrics_list = []

    with torch.no_grad():
        for i in range(N):
            train_pred, train_cls = generators[i](train_xes[i])
            train_pred = train_pred.cpu().numpy()
            train_pred_inv = inverse_transform(train_pred, y_scaler)
            train_preds_inv.append(train_pred_inv)
            train_metrics = compute_metrics(train_y_inv, train_pred_inv)
            train_metrics_list.append(train_metrics)
            plot_fitting_curve(train_y_inv, train_pred_inv, output_dir, f'G{i+1}_Train')
            print(f"Train Metrics for G{i+1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")
            logging.info(f"Train Metrics for G{i+1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")

        for i in range(N):
            test_pred, test_cls = generators[i](test_xes[i])
            test_pred = test_pred.cpu().numpy()
            test_pred_inv = inverse_transform(test_pred, y_scaler)
            test_preds_inv.append(test_pred_inv)
            test_metrics = compute_metrics(test_y_inv, test_pred_inv)
            test_metrics_list.append(test_metrics)
            plot_fitting_curve(test_y_inv, test_pred_inv, output_dir, f'G{i+1}_Test')
            print(f"Test Metrics for G{i+1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")
            logging.info(f"Test Metrics for G{i+1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")

    # æ„é€ è¿”å›ç»“æœ
    result = {
        "train_mse":  [m[0] for m in train_metrics_list],
        "train_mae":  [m[1] for m in train_metrics_list],
        "train_rmse": [m[2] for m in train_metrics_list],
        "train_mape": [m[3] for m in train_metrics_list],
        "train_mse_per_target": [m[4] for m in train_metrics_list],

        "test_mse":  [m[0] for m in test_metrics_list],
        "test_mae":  [m[1] for m in test_metrics_list],
        "test_rmse": [m[2] for m in test_metrics_list],
        "test_mape": [m[3] for m in test_metrics_list],
        "test_mse_per_target": [m[4] for m in test_metrics_list],
    }

    return result


def evaluate_best_models_with_return(generators, best_model_state, train_xes, train_y, test_xes, test_y, y_scaler,
                                     output_dir):
    N = len(generators)

    # åŠ è½½æ¨¡å‹å¹¶è®¾ä¸º eval
    for i in range(N):
        generators[i].load_state_dict(best_model_state[i])
        generators[i].eval()

    train_y_inv = inverse_transform(train_y, y_scaler)
    test_y_inv = inverse_transform(test_y, y_scaler)

    train_preds_inv = []
    test_preds_inv = []
    train_metrics_list = []
    test_metrics_list = []
    train_financial_metrics = []
    test_financial_metrics = []

    with torch.no_grad():
        for i in range(N):
            # è®­ç»ƒé›†é¢„æµ‹
            train_pred, train_cls = generators[i](train_xes[i])
            train_pred = train_pred.cpu().numpy()
            train_pred_inv = inverse_transform(train_pred, y_scaler)
            train_preds_inv.append(train_pred_inv)

            # è®¡ç®—è®­ç»ƒé›†çš„æ™®é€šæŒ‡æ ‡
            train_metrics = compute_metrics(train_y_inv, train_pred_inv)
            train_metrics_list.append(train_metrics)

            # è®¡ç®—è®­ç»ƒé›†çš„è´¢åŠ¡æŒ‡æ ‡
            train_returns = calculate_returns(train_y_inv.flatten(), train_cls.argmax(dim=-1).cpu().numpy())
            train_financial_metrics.append(calculate_metrics(train_returns))

            # ç»˜åˆ¶è®­ç»ƒé›†æ‹Ÿåˆæ›²çº¿
            plot_fitting_curve(train_y_inv, train_pred_inv, output_dir, f'G{i+1}_Train')
            print(f"Train Metrics for G{i+1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")
            logging.info(f"Train Metrics for G{i+1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")

        for i in range(N):
            # æµ‹è¯•é›†é¢„æµ‹
            test_pred, test_cls = generators[i](test_xes[i])
            test_pred = test_pred.cpu().numpy()
            test_pred_inv = inverse_transform(test_pred, y_scaler)
            test_preds_inv.append(test_pred_inv)

            # è®¡ç®—æµ‹è¯•é›†çš„æ™®é€šæŒ‡æ ‡
            test_metrics = compute_metrics(test_y_inv, test_pred_inv)
            test_metrics_list.append(test_metrics)

            # è®¡ç®—æµ‹è¯•é›†çš„è´¢åŠ¡æŒ‡æ ‡
            test_returns = calculate_returns(test_y_inv.flatten(), test_cls.argmax(dim=-1).cpu().numpy())
            test_financial_metrics.append(calculate_metrics(test_returns))

            # ç»˜åˆ¶æµ‹è¯•é›†æ‹Ÿåˆæ›²çº¿
            plot_fitting_curve(test_y_inv, test_pred_inv, output_dir, f'G{i+1}_Test')
            print(f"Test Metrics for G{i+1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")
            logging.info(f"Test Metrics for G{i+1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")

    # æ„é€ è¿”å›ç»“æœ
    result = {
        "train_mse":  [m[0] for m in train_metrics_list],
        "train_mae":  [m[1] for m in train_metrics_list],
        "train_rmse": [m[2] for m in train_metrics_list],
        "train_mape": [m[3] for m in train_metrics_list],
        "train_mse_per_target": [m[4] for m in train_metrics_list],

        "test_mse":  [m[0] for m in test_metrics_list],
        "test_mae":  [m[1] for m in test_metrics_list],
        "test_rmse": [m[2] for m in test_metrics_list],
        "test_mape": [m[3] for m in test_metrics_list],
        "test_mse_per_target": [m[4] for m in test_metrics_list],

        # æ·»åŠ è´¢åŠ¡æŒ‡æ ‡
        "train_financial_metrics": train_financial_metrics,
        "test_financial_metrics": test_financial_metrics,
    }

    return result

def append_financial_metrics(metrics_history, results_financial, epoch):
    """
    å°†æ¯ä¸ªepochæ‰€æœ‰ç”Ÿæˆå™¨çš„è´¢åŠ¡æŒ‡æ ‡è¿½åŠ åˆ°å†å²åˆ—è¡¨ã€‚
    æ¯ä¸ªç”Ÿæˆå™¨çš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†æŒ‡æ ‡éƒ½å•ç‹¬ä½œä¸ºä¸€åˆ—ã€‚
    """
    row = {'epoch': epoch + 1}
    for i, result in enumerate(results_financial):
        train_metrics = result['train_metrics']
        val_metrics = result['val_metrics']
        # è®­ç»ƒé›†
        row[f'G{i+1}_train_sharpe_ratio'] = train_metrics['sharpe_ratio']
        row[f'G{i+1}_train_calmar_ratio'] = train_metrics['calmar_ratio']
        row[f'G{i+1}_train_max_drawdown'] = train_metrics['max_drawdown']
        row[f'G{i+1}_train_annualized_return'] = train_metrics['annualized_return']
        row[f'G{i+1}_train_win_rate'] = train_metrics['win_rate']
        # æµ‹è¯•é›†
        row[f'G{i+1}_val_sharpe_ratio'] = val_metrics['sharpe_ratio']
        row[f'G{i+1}_val_calmar_ratio'] = val_metrics['calmar_ratio']
        row[f'G{i+1}_val_max_drawdown'] = val_metrics['max_drawdown']
        row[f'G{i+1}_val_annualized_return'] = val_metrics['annualized_return']
        row[f'G{i+1}_val_win_rate'] = val_metrics['win_rate']
    metrics_history.append(row)

def save_financial_metrics_csv(metrics_history, output_dir):
    """
    ä¿å­˜æ‰€æœ‰epochçš„è´¢åŠ¡æŒ‡æ ‡åˆ°CSVæ–‡ä»¶ï¼Œæ–‡ä»¶åè‡ªåŠ¨å‘½åä¸º financial_metrics_history.csv
    """
    os.makedirs(output_dir, exist_ok=True)
    csv_path = os.path.join(output_dir, "financial_metrics_history.csv")
    df = pd.DataFrame(metrics_history)
    df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    print(f"è´¢åŠ¡æŒ‡æ ‡å·²ä¿å­˜åˆ°: {csv_path}")
