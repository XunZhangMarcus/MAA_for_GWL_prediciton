import torch.nn.functional as F
import os
from sklearn.metrics import mean_squared_error, mean_absolute_error
import numpy as np
import torch
import matplotlib.pyplot as plt
import logging


# å¹´åŒ–æ”¶ç›Š
def calculate_annualized_return(returns, periods_per_year=252):
    cumulative_return = np.prod([1 + r for r in returns]) - 1
    years = len(returns) / periods_per_year
    if years == 0:
        return 0
    annualized_return = (1 + cumulative_return) ** (1 / years) - 1
    return annualized_return * 100


# å¤æ™®æ¯”ç‡ï¼ˆé»˜è®¤æ— é£é™©åˆ©ç‡ä¸º0ï¼‰
def calculate_sharpe_ratio(returns, periods_per_year=252):
    excess_returns = np.array(returns)
    mean_excess = np.mean(excess_returns)
    std_excess = np.std(excess_returns)
    if std_excess == 0:
        return 0
    sharpe = (mean_excess * np.sqrt(periods_per_year)) / std_excess
    return sharpe


# æœ€å¤§å›æ’¤
def calculate_max_drawdown(returns):
    cumulative_returns = np.cumprod([1 + r for r in returns])
    peak = np.maximum.accumulate(cumulative_returns)
    drawdowns = (cumulative_returns - peak) / peak
    max_drawdown = np.min(drawdowns)
    return abs(max_drawdown) * 100


# èƒœç‡ï¼ˆå¯é€‰ï¼‰
def calculate_win_rate(returns):
    returns = np.array(returns)
    profitable_trades = np.sum(returns > 0)
    total_trades = np.sum(returns != 0)
    return (profitable_trades / total_trades) * 100 if total_trades > 0 else 0


def calculate_returns(prices, pred_labels):
    """
    è®¡ç®—ç»™å®šä»·æ ¼æ•°æ®å’Œé¢„æµ‹åŠ¨ä½œçš„å›æŠ¥ã€‚

    Args:
    - prices (np.array): ä»·æ ¼æ•°æ®ã€‚
    - pred_labels (np.array): é¢„æµ‹çš„åŠ¨ä½œæ ‡ç­¾ï¼Œ0 = hold, 1 = buy, 2 = sell

    Returns:
    - returns (list): å›æŠ¥åˆ—è¡¨ã€‚
    """
    returns = []
    for i in range(1, len(prices)):
        price_change = (prices[i] - prices[i - 1]) / prices[i - 1]
        action = pred_labels[i]
        if action == 1:  # åšå¤šï¼ˆBuyï¼‰
            returns.append(price_change)
        elif action == 2:  # åšç©ºï¼ˆSellï¼‰
            returns.append(-price_change)
        else:  # æŒæœ‰ï¼ˆHoldï¼‰
            returns.append(0)
    return returns


def calculate_metrics(returns, periods_per_year=252):
    """
    è®¡ç®—è´¢åŠ¡æŒ‡æ ‡ï¼ˆSharpe Ratio, Max Drawdown, Annualized Return, Win Rateï¼‰

    Args:
    - returns (list): å›æŠ¥æ•°æ®ã€‚
    - periods_per_year (int): æ¯å¹´äº¤æ˜“æ—¥æ•°ï¼ˆé»˜è®¤252ï¼‰ã€‚

    Returns:
    - metrics (dict): åŒ…å«è´¢åŠ¡æŒ‡æ ‡çš„å­—å…¸ã€‚
    """
    sharpe_ratio = calculate_sharpe_ratio(returns, periods_per_year)
    max_drawdown = calculate_max_drawdown(returns)
    annualized_return = calculate_annualized_return(returns, periods_per_year)
    win_rate = calculate_win_rate(returns)

    return {
        'sharpe_ratio': round(sharpe_ratio, 4),
        'max_drawdown': round(max_drawdown, 2),
        'annualized_return': round(annualized_return, 2),
        'win_rate': round(win_rate, 2)
    }


def get_model_predictions(generator, x_data):
    """
    è·å–æ¨¡å‹çš„é¢„æµ‹ç»“æœã€‚

    Args:
    - generator (torch.nn.Module): è®­ç»ƒå¥½çš„ç”Ÿæˆå™¨æ¨¡å‹ã€‚
    - x_data (torch.Tensor): è¾“å…¥æ•°æ®ã€‚

    Returns:
    - pred (np.array): é¢„æµ‹çš„ç›®æ ‡å€¼ã€‚
    - pred_labels (np.array): é¢„æµ‹çš„åˆ†ç±»æ ‡ç­¾ã€‚
    """
    with torch.no_grad():
        pred, pred_cls = generator(x_data)
        pred = pred.cpu().numpy()
        pred_labels = pred_cls.argmax(dim=-1).cpu().numpy()
    return pred, pred_labels


def validate_financial_metric(generator, train_x, train_y, val_x, val_y, y_scaler):
    """
    éªŒè¯æ¨¡å‹çš„è´¢åŠ¡æŒ‡æ ‡ã€‚

    Args:
    - generator (torch.nn.Module): è®­ç»ƒå¥½çš„æ¨¡å‹ã€‚
    - train_x (torch.Tensor): è®­ç»ƒç‰¹å¾æ•°æ®ã€‚
    - train_y (torch.Tensor): è®­ç»ƒçœŸå®æ ‡ç­¾ã€‚
    - val_x (torch.Tensor): æµ‹è¯•ç‰¹å¾æ•°æ®ã€‚
    - val_y (torch.Tensor): æµ‹è¯•çœŸå®æ ‡ç­¾ã€‚
    - y_scaler (scaler): ç›®æ ‡æ•°æ®çš„æ ‡å‡†åŒ–å™¨ã€‚

    Returns:
    - train_metrics_list (list): è®­ç»ƒé›†çš„è´¢åŠ¡æŒ‡æ ‡åˆ—è¡¨ã€‚
    - val_metrics_list (list): æµ‹è¯•é›†çš„è´¢åŠ¡æŒ‡æ ‡åˆ—è¡¨ã€‚
    """
    # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    generator.eval()
    device = train_x.device  # è·å–è¾“å…¥æ•°æ®çš„è®¾å¤‡

    # è·å–è®­ç»ƒå’Œæµ‹è¯•é›†çš„é¢„æµ‹
    with torch.no_grad():
        _, train_pred_labels = get_model_predictions(generator, train_x)
        _, test_pred_labels = get_model_predictions(generator, val_x)

    # åå‘å˜æ¢ç›®æ ‡å˜é‡ï¼ˆåœ¨CPUä¸Šè¿›è¡Œï¼‰
    train_y_inv = inverse_transform(train_y.cpu(), y_scaler)
    val_y_inv = inverse_transform(val_y.cpu(), y_scaler)

    # è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›æŠ¥
    train_returns = calculate_returns(train_y_inv.flatten(), train_pred_labels)
    test_returns = calculate_returns(val_y_inv.flatten(), test_pred_labels)

    # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
    train_metrics = calculate_metrics(train_returns)
    val_metrics = calculate_metrics(test_returns)

    return [train_metrics], [val_metrics]


def evaluate_best_solution(y_scaler, train_y, val_y, train_label_y, val_label_y):
    train_y_inv = inverse_transform(train_y, y_scaler)
    val_y_inv = inverse_transform(val_y, y_scaler)
    train_label_y = train_label_y[:, -1].cpu().numpy()  # è½¬æ¢ä¸º NumPy æ•°ç»„
    val_label_y = val_label_y[:, -1].cpu().numpy()  # è½¬æ¢ä¸º NumPy æ•°ç»„

    # è®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å›æŠ¥
    train_returns = calculate_returns(train_y_inv.flatten(), train_label_y)
    val_returns = calculate_returns(val_y_inv.flatten(), val_label_y)

    # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡
    train_metrics = calculate_metrics(train_returns)
    val_metrics = calculate_metrics(val_returns)
    print("---------------------------\nPerfect Solution:")
    # æ‰“å°å¹¶è¿”å›ç»“æœ
    print("Train Metrics:", train_metrics)
    print("Val Metrics:", val_metrics)

    return train_metrics, val_metrics


def validate(model, val_x, val_y, val_label_y, predict_step=1, device='cuda'):
    model.eval()
    model = model.to(device)  # âœ… æ¨¡å‹ç§»åˆ° device
    with torch.no_grad():
        # âœ… æ‰€æœ‰æ•°æ®éƒ½ç§»åˆ° device
        val_x = val_x.clone().detach().float().to(device)

        if isinstance(val_y, np.ndarray):
            val_y = torch.tensor(val_y).float()
        val_y = val_y.clone().detach().float().to(device)

        if isinstance(val_label_y, np.ndarray):
            val_label_y = torch.tensor(val_label_y).long()
        val_label_y = val_label_y.clone().detach().long().to(device)

        # æ¨¡å‹é¢„æµ‹
        reg_preds, cls_preds = model(val_x)

        # é¢„æµ‹ & æ ‡ç­¾éƒ½åœ¨ device ä¸Šï¼Œæ­¤å¤„æ— éœ€å†è½¬
        reg_preds = reg_preds[:, -predict_step:]

        val_y = val_y[:, -predict_step:].squeeze(-1)
        if predict_step > 1:
            val_y = val_y.squeeze(dim=1)
        mse_loss = F.mse_loss(reg_preds, val_y)

        cls_preds = cls_preds[:, -predict_step:, :]
        cls_targets = val_label_y[:, -predict_step:]

        pred_labels = cls_preds.argmax(dim=-1)
        pred_labels = pred_labels.long()
        cls_targets = cls_targets.long()

        # print(pred_labels.shape, cls_targets.shape,cls_targets.numel())
        acc = (pred_labels == cls_targets).sum() / (cls_targets.numel())

    return mse_loss.item(), acc.item()


def validate_with_label(model, val_x, val_y, val_labels):
    model.eval()  # å°†æ¨¡å‹è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    with torch.no_grad():  # ç¦æ­¢è®¡ç®—æ¢¯åº¦
        val_x = val_x.clone().detach().float()

        # æ£€æŸ¥val_yçš„ç±»å‹ï¼Œå¦‚æœæ˜¯numpy.ndarrayåˆ™è½¬æ¢ä¸ºtorch.Tensor
        if isinstance(val_y, np.ndarray):
            val_y = torch.tensor(val_y).float()
        else:
            val_y = val_y.clone().detach().float()

        # labels ç”¨äºåˆ†ç±»
        if isinstance(val_labels, np.ndarray):
            val_lbl_t = torch.tensor(val_labels).long().to(val_x.device)
        else:
            val_lbl_t = val_labels.clone().detach().long().to(val_x.device)

        # ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        predictions, logits = model(val_x)
        predictions = predictions.cpu().numpy()
        val_y = val_y.cpu().numpy()

        # è®¡ç®—å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ä½œä¸ºéªŒè¯æŸå¤±
        mse_loss = F.mse_loss(torch.tensor(predictions).float().squeeze(), torch.tensor(val_y).float().squeeze())

        true_cls = val_lbl_t[:, -1].squeeze()  # [B]
        pred_cls = logits.argmax(dim=1)  # [B]
        acc = (pred_cls == true_cls).float().mean()  # æ ‡é‡

        return mse_loss, acc


def print_metrics(train_metrics_list, val_metrics_list):
    print("ğŸ“Š å›æµ‹ç»“æœæŒ‡æ ‡ï¼ˆæ¯è½®ï¼‰")
    print("=" * 40)
    for i, (train_metrics, val_metrics) in enumerate(zip(train_metrics_list, val_metrics_list)):
        print("  ğŸ“˜ è®­ç»ƒé›†:")
        print(f"    Sharpe Ratio       : {train_metrics['sharpe_ratio']}")
        print(f"    Max Drawdown       : {train_metrics['max_drawdown']}%")
        print(f"    Annualized Return  : {train_metrics['annualized_return']}%")
        print(f"    Win Rate           : {train_metrics.get('win_rate', 'N/A')}%")
        print("  ğŸ“• æµ‹è¯•é›†:")
        print(f"    Sharpe Ratio       : {val_metrics['sharpe_ratio']}")
        print(f"    Max Drawdown       : {val_metrics['max_drawdown']}%")
        print(f"    Annualized Return  : {val_metrics['annualized_return']}%")
        print(f"    Win Rate           : {val_metrics.get('win_rate', 'N/A')}%")
        print("-" * 40)


def plot_generator_losses(data_G, output_dir):
    """
    ç»˜åˆ¶ G1ã€G2ã€G3 çš„æŸå¤±æ›²çº¿ã€‚

    Args:
        data_G1 (list): G1 çš„æŸå¤±æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å« [histD1_G1, histD2_G1, histD3_G1, histG1]ã€‚
        data_G2 (list): G2 çš„æŸå¤±æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å« [histD1_G2, histD2_G2, histD3_G2, histG2]ã€‚
        data_G3 (list): G3 çš„æŸå¤±æ•°æ®åˆ—è¡¨ï¼ŒåŒ…å« [histD1_G3, histD2_G3, histD3_G3, histG3]ã€‚
    """

    plt.rcParams.update({'font.size': 12})
    all_data = data_G
    N = len(all_data)
    plt.figure(figsize=(6 * N, 5))

    for i, data in enumerate(all_data):
        plt.subplot(1, N, i + 1)
        for j, acc in enumerate(data):
            plt.plot(acc, label=f"G{i + 1} vs D{j + 1}" if j < N - 1 else f"G{i + 1} Combined", linewidth=2)

        plt.xlabel("Epoch", fontsize=14)
        plt.ylabel("Loss", fontsize=14)
        plt.title(f"G{i + 1} Loss over Epochs", fontsize=16)
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "generator_losses.png"), dpi=500)
    plt.close()


def plot_discriminator_losses(data_D, output_dir):
    plt.rcParams.update({'font.size': 12})
    N = len(data_D)
    plt.figure(figsize=(6 * N, 5))

    for i, data in enumerate(data_D):
        plt.subplot(1, N, i + 1)
        for j, acc in enumerate(data):
            plt.plot(acc, label=f"D{i + 1} vs G{j + 1}" if j < len(data) - 1 else f"D{i + 1} Combined", linewidth=2)

        plt.xlabel("Epoch", fontsize=14)
        plt.ylabel("Loss", fontsize=14)
        plt.title(f"D{i + 1} Loss over Epochs", fontsize=16)
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "discriminator_losses.png"), dpi=500)
    plt.close()


def visualize_overall_loss(histG, histD, output_dir):
    plt.rcParams.update({'font.size': 12})
    N = len(histG)
    plt.figure(figsize=(5 * N, 4))

    for i, (g, d) in enumerate(zip(histG, histD)):
        plt.plot(g, label=f"G{i + 1} Loss", linewidth=2)
        plt.plot(d, label=f"D{i + 1} Loss", linewidth=2)

    plt.xlabel("Epoch", fontsize=14)
    plt.ylabel("Loss", fontsize=14)
    plt.title("Generator & Discriminator Loss", fontsize=16)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "overall_losses.png"), dpi=500)
    plt.close()


def plot_mse_loss(hist_MSE_G, hist_val_loss, num_epochs,
                  output_dir):
    """
    ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­å’ŒéªŒè¯é›†ä¸Šçš„MSEæŸå¤±å˜åŒ–æ›²çº¿

    å‚æ•°ï¼š
    hist_MSE_G1, hist_MSE_G2, hist_MSE_G3 : è®­ç»ƒè¿‡ç¨‹ä¸­å„ç”Ÿæˆå™¨çš„MSEæŸå¤±
    hist_val_loss1, hist_val_loss2, hist_val_loss3 : éªŒè¯é›†ä¸Šå„ç”Ÿæˆå™¨çš„MSEæŸå¤±
    num_epochs : è®­ç»ƒçš„epochæ•°
    """
    plt.rcParams.update({'font.size': 12})
    N = len(hist_MSE_G)
    plt.figure(figsize=(5 * N, 4))

    for i, (MSE, val_loss) in enumerate(zip(hist_MSE_G, hist_val_loss)):
        plt.plot(range(num_epochs), MSE, label=f"Train MSE G{i + 1}", linewidth=2)
        plt.plot(range(num_epochs), val_loss, label=f"Val MSE G{i + 1}", linewidth=2, linestyle="--")

    plt.title("MSE Loss for Generators (Train vs Validation)", fontsize=16)
    plt.xlabel("Epoch", fontsize=14)
    plt.ylabel("MSE", fontsize=14)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, "mse_losses.png"), dpi=500)
    plt.close()


def inverse_transform(predictions, scaler):
    """ ä½¿ç”¨y_scaleré€†è½¬æ¢é¢„æµ‹ç»“æœ """
    # ç¡®ä¿æ•°æ®åœ¨CPUä¸Š
    if isinstance(predictions, torch.Tensor):
        predictions = predictions.cpu().numpy()

    original_shape = predictions.shape
    reshaped = predictions.reshape(-1, original_shape[-1])  # (batch * steps, 1)
    restored = scaler.inverse_transform(reshaped)
    return restored


def compute_metrics(true_values, predicted_values):
    """è®¡ç®—MSE, MAE, RMSE, MAPE"""
    mse = mean_squared_error(true_values, predicted_values)
    mae = mean_absolute_error(true_values, predicted_values)
    rmse = np.sqrt(mse)
    mape = np.mean(np.abs((true_values - predicted_values) / true_values)) * 100
    per_target_mse = np.mean((true_values - predicted_values) ** 2, axis=0)  # æ–°å¢
    return mse, mae, rmse, mape, per_target_mse


def plot_fitting_curve(true_values, predicted_values, output_dir, model_name):
    """ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿å¹¶ä¿å­˜ç»“æœ"""
    plt.rcParams.update({'font.size': 12})
    plt.figure(figsize=(10, 6))
    plt.plot(true_values, label='True Values', linewidth=2)
    plt.plot(predicted_values, label='Predicted Values', linewidth=2, linestyle='--')
    plt.title(f'{model_name} Fitting Curve', fontsize=16)
    plt.xlabel('Time', fontsize=14)
    plt.ylabel('Value', fontsize=14)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(f'{output_dir}/{model_name}_fitting_curve.png', dpi=500)
    plt.close()


def save_metrics(metrics, output_dir, model_name):
    """ä¿å­˜MSE, MAE, RMSE, MAPEåˆ°æ–‡ä»¶"""
    with open(f'{output_dir}/{model_name}_metrics.txt', 'w') as f:
        f.write("MSE: {}\n".format(metrics[0]))
        f.write("MAE: {}\n".format(metrics[1]))
        f.write("RMSE: {}\n".format(metrics[2]))
        f.write("MAPE: {}\n".format(metrics[3]))


def evaluate_best_models(generators, best_model_state, train_xes, train_y, test_xes, test_y, y_scaler, output_dir):
    N = len(generators)

    # åŠ è½½æ¨¡å‹å¹¶è®¾ä¸º eval
    for i in range(N):
        generators[i].load_state_dict(best_model_state[i])
        generators[i].eval()

    train_y_inv = inverse_transform(train_y, y_scaler)
    test_y_inv = inverse_transform(test_y, y_scaler)

    train_preds_inv = []
    test_preds_inv = []
    train_metrics_list = []
    test_metrics_list = []

    with torch.no_grad():
        for i in range(N):
            train_pred, train_cls = generators[i](train_xes[i])
            train_pred = train_pred.cpu().numpy()
            train_pred_inv = inverse_transform(train_pred, y_scaler)
            train_preds_inv.append(train_pred_inv)
            train_metrics = compute_metrics(train_y_inv, train_pred_inv)
            train_metrics_list.append(train_metrics)
            plot_fitting_curve(train_y_inv, train_pred_inv, output_dir, f'G{i + 1}_Train')
            print(
                f"Train Metrics for G{i + 1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")
            logging.info(
                f"Train Metrics for G{i + 1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")

        for i in range(N):
            test_pred, test_cls = generators[i](test_xes[i])
            test_pred = test_pred.cpu().numpy()
            test_pred_inv = inverse_transform(test_pred, y_scaler)
            test_preds_inv.append(test_pred_inv)
            test_metrics = compute_metrics(test_y_inv, test_pred_inv)
            test_metrics_list.append(test_metrics)
            plot_fitting_curve(test_y_inv, test_pred_inv, output_dir, f'G{i + 1}_Test')
            print(
                f"Test Metrics for G{i + 1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")
            logging.info(
                f"Test Metrics for G{i + 1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")

    # æ„é€ è¿”å›ç»“æœ
    result = {
        "train_mse": [m[0] for m in train_metrics_list],
        "train_mae": [m[1] for m in train_metrics_list],
        "train_rmse": [m[2] for m in train_metrics_list],
        "train_mape": [m[3] for m in train_metrics_list],
        "train_mse_per_target": [m[4] for m in train_metrics_list],

        "test_mse": [m[0] for m in test_metrics_list],
        "test_mae": [m[1] for m in test_metrics_list],
        "test_rmse": [m[2] for m in test_metrics_list],
        "test_mape": [m[3] for m in test_metrics_list],
        "test_mse_per_target": [m[4] for m in test_metrics_list],
    }

    return result


def evaluate_best_models_for_backtrader(generators, best_model_state, train_xes, train_y, test_xes, test_y, y_scaler, output_dir):
    N = len(generators)

    # åŠ è½½æ¨¡å‹å¹¶è®¾ä¸º eval
    for i in range(N):
        generators[i].load_state_dict(best_model_state[i])
        generators[i].eval()

    train_y_inv = inverse_transform(train_y, y_scaler)
    test_y_inv = inverse_transform(test_y, y_scaler)

    train_preds_inv = []
    test_preds_inv = []
    train_metrics_list = []
    test_metrics_list = []

    with torch.no_grad():
        for i in range(N):
            train_pred, train_cls = generators[i](train_xes[i])
            train_pred = train_pred.cpu().numpy()
            train_pred_inv = inverse_transform(train_pred, y_scaler)
            train_preds_inv.append(train_pred_inv)
            train_metrics = compute_metrics(train_y_inv, train_pred_inv)
            train_metrics_list.append(train_metrics)
            plot_fitting_curve(train_y_inv, train_pred_inv, output_dir, f'G{i + 1}_Train')
            print(
                f"Train Metrics for G{i + 1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")
            logging.info(
                f"Train Metrics for G{i + 1}: MSE={train_metrics[0]:.4f}, MAE={train_metrics[1]:.4f}, RMSE={train_metrics[2]:.4f}, MAPE={train_metrics[3]:.4f}")

        for i in range(N):
            test_pred, test_cls = generators[i](test_xes[i])
            test_pred = test_pred.cpu().numpy()
            test_pred_inv = inverse_transform(test_pred, y_scaler)
            test_preds_inv.append(test_pred_inv)
            test_metrics = compute_metrics(test_y_inv, test_pred_inv)
            test_metrics_list.append(test_metrics)
            plot_fitting_curve(test_y_inv, test_pred_inv, output_dir, f'G{i + 1}_Test')
            print(
                f"Test Metrics for G{i + 1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")
            logging.info(
                f"Test Metrics for G{i + 1}: MSE={test_metrics[0]:.4f}, MAE={test_metrics[1]:.4f}, RMSE={test_metrics[2]:.4f}, MAPE={test_metrics[3]:.4f}")

    # æ„é€ è¿”å›ç»“æœ
    result = {
        "train_mse": [m[0] for m in train_metrics_list],
        "train_mae": [m[1] for m in train_metrics_list],
        "train_rmse": [m[2] for m in train_metrics_list],
        "train_mape": [m[3] for m in train_metrics_list],
        "train_mse_per_target": [m[4] for m in train_metrics_list],

        "test_mse": [m[0] for m in test_metrics_list],
        "test_mae": [m[1] for m in test_metrics_list],
        "test_rmse": [m[2] for m in test_metrics_list],
        "test_mape": [m[3] for m in test_metrics_list],
        "test_mse_per_target": [m[4] for m in test_metrics_list],

        "test_preds_inv": test_preds_inv,
    }

    return result

